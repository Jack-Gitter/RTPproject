High level approach: 

The high level approach that was taken for this project is quite similar to the outlined approach described and recommended by the project. First a basic window size was implemented in order to be able to control the amount of packets that were in the network at once. Then an ID field was added to the header of an ack to detect for acks that were duplicated by the network, this id field was just incremented once each time an ack was sent, and any duplicate number was detected by the sender as a duplicated ack by the network. The same functionality was able to be achieved at the receiver end with just sns, as the packets would be buffered. In order to deal with out of order packets, a buffer was created on the receiver side that kept any messages that were actually received by the receiver, and acknowledged all of the individual messages themselves effectively implementing SACK. Each time a new message would be received, the receiver would check to see if the message was in order using an SN + data length calculation, and print out all of the messages it could if so using the buffer. Then RTT/RTO functionality was implemented for each sent out packet, which just checks if the packet has been out for a specific amount of time without an ack, then resend it. This is checked every .1 second to minimize delay after RTO has expired (RTT time was 1 second, and check for expiration every .1 seconds). A checksum was then implmeneted using hashlib which hashed all of the data fields within the header, and added the checksum to the header. This was added for both the sender and receiver, and also a check was made to ensure that the data was in proper JSON format so that it could be decoded in the first place. Then a simple calculation was performed to change the RTO based on the speed that packets were being ack'd by the network, and this would occur each time a packet was ack'd, and ignored if a packet was dropped by the network from the sender. Finally variable window sizing was implemented, and each time a packet was detected to be dropped the window size decreased in order to avoid overflowing router queues. For data stuctures, a priority queue was used on the receiver side to buffer data based on the sn number making it efficient to see the lowest sn number that the receiver currently has, and to process them in order. Most other information was stored in either dictionaries or arrays as there was no particular efficient was to sort 

Challenges

The real main challenge that was faced for this project was implementing drop detection and resending packets, as after this the rest of the functionality came quite quickly. It was challenging figuring out which variant of TCP to base the solution from, as one that was extremely complex would be labor intensive, although a simpler version would not perform great. It was eventually decided to use SACK, as it struck a good balance between the aformentioned tradeoffs. Additionally at first the checksum was attempted to be implemented manually without the use of hashlib, which was eventually a failure and hashlib was then used

Properties of code that are good
The receiver buffers information using a priority queue, which makes it O(1) to figure out if the data the receiver has can be printed out. If it can be, then it is order O(n) to print out every single item that the receiver has in the worst case, as it can just keep peeking at the front of the queue in order to check if the item is in order, or if it is waiting for any extra packets to arrive before printing out. Additionally SACK is implemented, so the sender does not need to resend unnecessary information to the receiver. Finally the checksum uses more than just the data field, it uses all of the values in the header. This ensures that if anything is wrong at all with the packet sent from the sender or receiver, their counterpart can detect it. Also using a hashing algorithm has high entropy, so it is practically impossible to get even a similar hash if a packet is corrupted.

Testing:
Testing was performed mainly with the provided test suite, and some manual testing was done in the early stages to learn about how the starter code worked
